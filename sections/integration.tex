\chapter{Multi-modal integration}
% TODO major: format citations
\section{Background}
The ability to dissect a tissue into its cellular components to study them individually or to investigate the interplay between the different cell type fractions is an exciting new possibility in biological research.
These lines of research have yielded important insights into the dynamics of various diseases, especially for cancer (Chevrier et al., 2017; Tirosh et al., 2016).
Recent advances in single-cell technologies enable molecular profiling of samples with greater granularity at the transcriptomic, proteomic, genomic as well as the functional assays level (Irmisch et al., 2020; Rozenblatt-Rosen et al., 2017).
While each of these data modalities offer insight into different types and levels of internal cellular processes,
a \textit{holistic} understanding of cellular state could be obtained through the combination or integration of these modalities.
Knowing the measurement of multiple modalities for individual cells would deepen our understanding of the cellular mechanisms at play in, for instance, the tissue microenvironment, and construct a comprehensive molecular view of profiled samples.s

A key challenge towards such integration, however, lies in the limitations of profiling technologies.
Since ubiquitous technologies, such as scRNA-seq and CyTOF, consume the profiled cells, it is typically not possible to observe these cells in more than one modality.
While technologies capable of measuring multiple modalities simultaneously are emerging (Stoeckius et al., 2017; Zhu et al., 2020), they remain limited in terms of scalability and practicality.
Thus, the multi-modal integration of cellular processes falls to computational methods.
Given observation datasets across individual profiling modalities, these methods typically assume that the samples profiled in each modality are somehow similar in composition, and perform integration bo constructing and \textit{alignment} across these datasets.
A critical complication towards this alignment lies in the weak correspondences between the feature sets over these modalities
For instance, there does not exist a one-to-one correspondence between genes (as profiled by scRNA-seq) and proteins (as profiled by CyTOF).
Thus, proper alignment is a challenging task.

%\bold{Related work}
While multiple data integration tools have been developed, most approaches either depend on or impose feature correspondences (Stuart et al., 2019; Welch et al., 2019), or are designed to applied to a limited set of modalities, for instance, scRNA and scDNA data (Campbell et al., 2019; McCarthy et al., 2020).
To the best of our knowledge only two other approaches have been published (Amodio and Krishnaswamy, 2018; Welch et al., 2017) able to perform integration over general modalities.
MAGAN (Amodio and Krishnaswamy, 2018) is a Generative Adversarial Network capable of aligning the manifold between two technologies that relies on a feature correspondence loss.
MATCHER (Welch et al., 2017) is based on a Gaussian process latent variable model (GPLVM) (Lawrence, 2004) that can integrate technologies if their underlying latent structures can be represented in one dimension, applicable, for example, to model monotonic temporal processes.
Other yet unpublished methods, such as MMD-MA (Liu et al., 2019) and UnionCom (Cao et al., 2020), rely on large kernel matrices which limit their scalability when using datasets of the sizes generally produced by molecular profiling.

Here, we propose Single-cell Integration via Matching (SCIM), a method to match cells across different single-cell ’omics technologies.
Our approach is universal, in the sense that it is in principle applicable to any single-cell technology and overcomes the scaling issues of contemporary approaches.
Further, we do not assume the existence of paired features between two technologies.
This allows for the integration of technologies that measure for example the expression of a disjoint set of genes, or the integration of gene expression with image features as long as the underlying latent structure is present in those features.

\section{Single-cell integration via Matching}
SCIM achieves multi-modal single-cell integration in two steps.
First, we construct an integrated latent space using an adversarial autoencoder framework (CITE) wherein representations are invariant to their corresponding technologies, inspired by a model proposed previously (Yang and Uhler, 2019) and further extended in Yang et al. (2019).
In the second step, we perform a strong pairwise alignment of datasets from each modality via a cell-to-cell matching strategy that efficiently extracts cross-technology cell matches from the latent space.
SCIM assumes a shared latent representation between technologies but, unlike other approaches, does not require one-to-one or overlapping correspondences between feature sets.
SCIM scales well in the number of cells in the input through the use of neural-nets, end-to-end training and an efficient bipartite matching algorithm.
Finally, this training scheme allows for the addition of an arbitrary number of technologies, which can be trained in parallel.

\subsection{Constructing technology-invariant representations}
SCIM encodes datasets into a shared latent space that is constructed to have two properties:
% TODO minor reference VAE section
First, inputs should be able to be reconstructed from their latent representations, as is typically achieved by vanilla VAEs.
2) the latent representations of each technology should be well-integrated such that they are indistinguishable from each other.
In a successful integration the resulting latent space will have corresponding cells across all technologies represented in close proximity.

To construct an integrated latent space, SCIM uses a modified adversarial auto encoder framework.
% TODO minor: explain source/target modalities
%First, one modality is chosen as the source modality and the other modalities are regarded as the target modalities.
This consists of the following networks: a pair of encoder ($\phi_k$) and decoder ($\psi_k$) networks for each technology $k$ and a single discriminator network ($\gamma$) acting on the latent space.
This discriminator is a binary classifier trained to identify the latent representation of some source technology from latent representations of all other technologies using a binary cross entropy loss.

SCIM yields an integrated latent space by minimizing the reconstruction error while adversarially fooling the discriminator.
Given the measurements of a batch of cells from the target modality $t$, $x_t$, and the (fixed) latent representations of a batch of cells from the source modality $s$, $\hat{z}_s \sim \phi_s(x_s)$,
% TODO major: fix SCIM equations, write as min-max
\begin{equation}
1 = 2
\end{equation}

$\mathcal{L}_{nll}$ is the negative log-likelihood of the inputs under their reconstruction.
$\mathcal{L}_{adv}$ is the discriminator’s classification error when trying to classify the latent representation samples $\hat{z}_s$ or $\hat{z}_t$ as the source or target technology.
$\beta$ is a hyperparameter weighing the influence of the adversarial loss.
%At the same time, c is trained to correct- ly classify the technology of the z^s and z^t samples.

\paragraph{Latent space orientation}
Correctly orienting the latent space in an unsupervised manner is a challenging task (Locatello et al., 2018; Yang and Uhler, 2019).
Consider, for example, a simple monotonic temporal process.
The latent representations for one dataset could be oriented from start to end, while another could be oriented from finish to start (Welch et al., 2017).
% TODO minor: fix eqn ref
Equation 2 is satisfied, the representations are well integrated and inputs can be correctly reconstructed from them, yet the inter-dataset relationships are misaligned.
Makhzani et al. (2015) address a similar problem by concatenating one-hot representations of labels reflecting intra-technology structure (e.g. cell type is an appropriate choice for ’omics datasets) to the discriminator inputs, showing that this supervision is necessary to orient the latent space.
Furthermore, Locatello et al. (2019) argued that only a small number of labels are actually needed to achieve orientation.
To this end, we adopt a semi-supervised approach by adding a ‘censored’ label and randomly relabel cells in the training set.

\paragraph{Model architecture}
Unless specified otherwise, we adopt the following architecture settings.
All networks use the ReLU activation. % TODO minor: cite/ref/describe ReLU?
We set the latent dimension of all models to eight, but observed this choice to be flexible.
We use discriminator networks with two layers and eight hidden units each.
% TODO major: describe spectral norm?
The Spectral Normalization framework (Miyato et al., 2018) is used during training, which has been argued to stabilize discriminator training by effectively bounding its gradients.
We use a Gaussian activation for all decoders, a 2 layer architecture with 64 hidden units for all simulated data networks, a 2 layer architecture with 8 hidden units for all CyTOF networks and a 2 layer architecture with 64 hidden units for all scRNA networks.
The number of features and complexity of data is considered when choosing capacity and depth.

\paragraph{Optimization}
Optimization proceeds by iteratively fixing one technology as the source and one technology as the target.
In the case of more than two technologies, the technology corresponding to the discriminator’s positive class must either be the source or target technology.
Optimization proceeds with an inner and outer loop.
% TODO minor: ref eqn correctly
In a single inner loop step, the latent representations of the source technology are fixed and Equation XX is minimized with gradient updates to the encoder and decoder of the target modality $t$ using gradients computed on the batch $x_t$.
This process is repeated multiple times and then one step of the outer loop is performed.
In a single outer loop step, the discriminator is updated to classify $z_s$ and $z_t$.
All networks are optimized using the ADAM algorithm (Kingma and Ba, 2014).


\paragraph{Model Selection}
Due to the min–max nature of adversarial training, model comparison is challenging since one cannot directly compare the minimized objective functions of converged models (Lucic et al., 2017).
While the computer vision community has introduced a number of metrics specific to the image domain to help compare models (Heusel et al., 2017; Salimans et al., 2016), here we need to validate the quality of a set of lower-dimensional latent representations.
To achieve this, we utilize a k-Nearest Neighbor (kNN)-based divergence estimator (Wang et al., 2009).
The divergence score between two sets of codes $Z_s$ and $Z_t$ is calculated as:
% TODO minor: typeset eqn
\begin{equation}
	a = b
\end{equation}
This estimator approximates a symmetric variant of a KL divergence, a measure of how much two distributions differ, using only empirical data.
The divergence estimate is computed between the latent representations of the source technology and the target technology to measure the alignment of codes from the two technologies.
Model selection can proceed at scale by selecting parameter configurations that align technology distributions and have low reconstruction error.

\subsection{Bipartite matching of single-cell embeddings}
In its second step, SCIM performs multi-modal integration by identifying pairs of corresponding cells across two modalities using their representations in the latent space constructed in the first step.
We identify pairs by solving a combinatorial bipartite matching problem (Ahuja et al., 1993; Dell’Amico and Toth, 2000), wherein the bipartite graph is constructed by connecting cells between each pair of technologies, weighted by their distances in the latent space.
The bipartite matching problem then identifies an optimal set of paired cells that minimizes the total edge cost of all matches.
In order to achieve this efficiently and at scale, we approximate the full bipartite graph with a k-Nearest Neighbors (kNN) graph that identifies a set of potential matches for each cell and reduces the complexity of the problem.
We then extend the graph to account for single-cell data characteristics and solve the bipartite matching within a general framework of Minimum-Cost Maximum-Flow problems (Ahuja et al., 1993; Klein, 1967).

\paragraph{kNN subgraph approximation}
Given the large number of cells in single-cell datasets, we reduce the search space to the $k$ most likely potential matches.
For each pairwise integration task, two kNN graphs are built: the first uses the source data queried by the target technology cells, and the second uses target data queried by the source technology
That is, each cell in the source technology is connected to its $k$ nearest neighbor cells in the target technology and each cell in the target technology is connected to its $k$ nearest neighbor cells in the source technology.
The union of this graph is then used in the bipartite matching solver.
The sparsity of these connections, regulated by the choice of the hyperparameter $k$, corresponds to a trade-off between the computational performance (memory usage, run time) and the final matching accuracy.

%\paragraph{Min\-cost Max\-flow matching}
Based on a Euclidean cost matrix, we aim at finding the maximum number of cell pairs with minimum cost.
This corresponds to finding a maximum flow that can be pushed through the graph, where each edge between cells has capacity 1, while minimizing the overall cost.
To solve the Minimum-Cost Maximum-Flow problem in a compu- tationally efficient way we use an implementation of the network simplex algorithm (Kira ́ly and Kova ́cs, 2012).















